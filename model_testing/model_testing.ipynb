{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\"test_data cs 1.csv\")  # Replace with actual dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns (assume target column is 'target')\n",
    "features = [col for col in data.columns if col != 'compare_text']\n",
    "target = 'compare_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'screen_name', 'user_lang', 'lang', 'time_zone', 'location',\n",
      "       'verified', 'friends_count', 'compare_text', 'source', 'created_at',\n",
      "       'favourites_count', 'listed_count', 'statuses_count', 'followers_count',\n",
      "       'label', 'cred_score', 'eye_truth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean missing data\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                 object\n",
      "screen_name          object\n",
      "user_lang            object\n",
      "lang                 object\n",
      "time_zone            object\n",
      "location             object\n",
      "verified             object\n",
      "friends_count         int64\n",
      "source               object\n",
      "created_at           object\n",
      "favourites_count      int64\n",
      "listed_count          int64\n",
      "statuses_count        int64\n",
      "followers_count       int64\n",
      "label                object\n",
      "cred_score            int64\n",
      "eye_truth           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data[features].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data[features]:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')  # Convert invalid strings to NaN\n",
    "data.dropna(inplace=True)  # Drop rows with NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data for Neural Network\n",
    "scaler = StandardScaler()\n",
    "data[features] = scaler.fit_transform(data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "data_selected = selector.fit_transform(data[features], data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_selected, data[target], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "87456    0.813037\n",
      "4168     0.830008\n",
      "41962    0.821274\n",
      "78294    0.845077\n",
      "13945    0.835596\n",
      "Name: compare_text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.dtype)\n",
    "print(y_train[:5])  # Preview first 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "[[ 0.18719771  0.18719771  0.54938101 -1.03329507 -1.13296478  0.02950662\n",
      "   1.29604484 -1.30342201 -0.09644502 -0.44429257]\n",
      " [ 1.68201181  1.68201181  1.26643951 -1.03329507 -1.13296478 -0.50661619\n",
      "  -1.57484965 -1.30342201 -0.09644502 -1.12313561]\n",
      " [ 1.63493105  1.63493105  1.26643951  0.96777777  0.88263997 -1.30392703\n",
      "  -0.29631364  0.46425248 -0.09644502 -0.3304408 ]\n",
      " [-0.16590798 -0.16590798 -0.16767749 -1.03329507  0.88263997  0.01575988\n",
      "   1.00546847  0.46425248 -0.09644502 -0.31531499]\n",
      " [ 0.69331587  0.69331587 -0.88473599 -1.03329507 -1.13296478 -0.12170751\n",
      "  -1.24940412  1.34808972 -0.09644502 -0.30331522]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtype)\n",
    "print(X_train[:5])  # Preview first 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network: MSE = 0.0001, R² = 0.5650, Cross-Validation Score = 0.4614\n",
      "Boosted Decision Tree: MSE = 0.0001, R² = 0.6362, Cross-Validation Score = 0.6464\n",
      "Linear Regression: MSE = 0.0001, R² = 0.0650, Cross-Validation Score = 0.0612\n"
     ]
    }
   ],
   "source": [
    "# Define regression models\n",
    "models = {\n",
    "    \"Neural Network\": MLPRegressor(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "    \"Boosted Decision Tree\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"Linear Regression\": LinearRegression()\n",
    "}\n",
    "\n",
    "# Train, score, and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation metrics for regression\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    cv_score = np.mean(cross_val_score(model, X_train, y_train, cv=5, scoring='r2'))\n",
    "\n",
    "    print(f\"{name}: MSE = {mse:.4f}, R² = {r2:.4f}, Cross-Validation Score = {cv_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the metrics\n",
    "\n",
    "MSE (Mean Squared Error): Measures the average squared difference between predicted and actual values. Lower values are better.\n",
    "\n",
    "R² (R-Squared): Indicates how well the model explains the variance in the target variable. Values closer to 1 mean better performance.\n",
    "\n",
    "Cross-Validation Score: The average R² score from multiple training/testing splits. Helps check for overfitting or generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparisons\n",
    "\n",
    "Neural Network (MLPRegressor)\n",
    "\n",
    "MSE = 0.0001 (Low error)\n",
    "R² = 0.5650 (Explains 56.5% of variance)\n",
    "CV Score = 0.4614 (Performance drops a bit on new data)\n",
    "Interpretation: The neural network performs decently, capturing some patterns in the data. However, the cross-validation score is lower, suggesting some overfitting.\n",
    "\n",
    "Boosted Decision Tree (Gradient Boosting Regressor)\n",
    "\n",
    "MSE = 0.0001 (Low error, similar to NN)\n",
    "R² = 0.6362 (Explains 63.6% of variance)\n",
    "CV Score = 0.6464 (Very close to R², meaning it's generalizing well)\n",
    "Interpretation: This is the best-performing model. It explains more variance than the neural network and has a strong cross-validation score, meaning it's generalizing better.\n",
    "\n",
    "Linear Regression\n",
    "\n",
    "MSE = 0.0001 (Low error, but similar to others)\n",
    "R² = 0.0650 (Explains only 6.5% of variance—very poor)\n",
    "CV Score = 0.0612 (Poor generalization)\n",
    "Interpretation: The linear model is weak at capturing patterns in the data. Since R² is close to 0, it suggests that the relationships in the dataset are likely nonlinear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "\n",
    "Gradient Boosting performed the best—it explains the most variance and generalizes well.\n",
    "Neural Network is okay but may be overfitting slightly.\n",
    "Linear Regression is not a good fit, likely because the data has complex relationships that it can't model well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
