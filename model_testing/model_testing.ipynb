{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\"test_data cs 1.csv\")  # Replace with actual dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns (assume target column is 'target')\n",
    "features = [col for col in data.columns if col != 'verified']\n",
    "target = 'verified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'screen_name', 'user_lang', 'lang', 'time_zone', 'location',\n",
      "       'verified', 'friends_count', 'compare_text', 'source', 'created_at',\n",
      "       'favourites_count', 'listed_count', 'statuses_count', 'followers_count',\n",
      "       'label', 'cred_score', 'eye_truth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean missing data\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                 object\n",
      "screen_name          object\n",
      "user_lang            object\n",
      "lang                 object\n",
      "time_zone            object\n",
      "location             object\n",
      "friends_count         int64\n",
      "compare_text        float64\n",
      "source               object\n",
      "created_at           object\n",
      "favourites_count      int64\n",
      "listed_count          int64\n",
      "statuses_count        int64\n",
      "followers_count       int64\n",
      "label                object\n",
      "cred_score            int64\n",
      "eye_truth           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data[features].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data[features]:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')  # Convert invalid strings to NaN\n",
    "data.dropna(inplace=True)  # Drop rows with NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data for Neural Network\n",
    "scaler = StandardScaler()\n",
    "data[features] = scaler.fit_transform(data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "data_selected = selector.fit_transform(data[features], data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_selected, data[target], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network: Accuracy = 0.9630, Cross-Validation Score = 0.9645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19373\n",
      "           1       0.00      0.00      0.00       743\n",
      "\n",
      "    accuracy                           0.96     20116\n",
      "   macro avg       0.48      0.50      0.49     20116\n",
      "weighted avg       0.93      0.96      0.94     20116\n",
      "\n",
      "Boosted Decision Tree: Accuracy = 0.9630, Cross-Validation Score = 0.9644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19373\n",
      "           1       0.33      0.00      0.00       743\n",
      "\n",
      "    accuracy                           0.96     20116\n",
      "   macro avg       0.65      0.50      0.49     20116\n",
      "weighted avg       0.94      0.96      0.95     20116\n",
      "\n",
      "Logistic Regression: Accuracy = 0.9631, Cross-Validation Score = 0.9645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     19373\n",
      "           1       0.00      0.00      0.00       743\n",
      "\n",
      "    accuracy                           0.96     20116\n",
      "   macro avg       0.48      0.50      0.49     20116\n",
      "weighted avg       0.93      0.96      0.94     20116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "models = {\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "    \"Boosted Decision Tree\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression()\n",
    "}\n",
    "\n",
    "# Train, score, and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cv_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "    print(f\"{name}: Accuracy = {accuracy:.4f}, Cross-Validation Score = {cv_score:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
